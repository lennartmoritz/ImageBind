{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/1moritz/miniforge3/envs/imagebind/lib/python3.9/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/srv/home/1moritz/miniforge3/envs/imagebind/lib/python3.9/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe1dc4ffbf540899c8e7fd22003e8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from easydict import EasyDict\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm as tqdm\n",
    "from imagebind import data\n",
    "from imagebind.models import imagebind_model\n",
    "from imagebind.models.imagebind_model import ModalityType\n",
    "\n",
    "class MyMSRVTT_DataLoader(Dataset):\n",
    "    \"\"\"MSRVTT dataset loader.\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            csv_path,\n",
    "            features_path,\n",
    "    ):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.features_path = features_path\n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_id = self.data['video_id'].values[idx]\n",
    "        sentence = self.data['sentence'].values[idx]\n",
    "\n",
    "        video_path = os.path.join(self.features_path, \"{}.mp4\".format(video_id))\n",
    "        return sentence, video_path\n",
    "    \n",
    "\n",
    "def get_args_msrvtt():\n",
    "    # build args\n",
    "    args = {\n",
    "        \"val_csv\": '/raid/1moritz/datasets//MSRVTT/MSRVTT_JSFUSION_test.csv',\n",
    "        \"features_path\": '/raid/1moritz/datasets//MSRVTT/MSRVTT_Videos',\n",
    "        \"batch_size_val\": 8,\n",
    "        \"num_thread_reader\": 1,\n",
    "        \"cache_dir\": '/raid/1moritz/models/languagebind/downloaded_weights',\n",
    "    }\n",
    "    args = EasyDict(args)\n",
    "    return args\n",
    "\n",
    "def run_msrvtt_eval(model: imagebind_model.ImageBindModel, dataloader: DataLoader, device: torch.device):\n",
    "    batch_sentences_embeddings, batch_videos_embeddings = [], []\n",
    "    # Calculate embeddings\n",
    "    for bid, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        sentences, video_paths = batch\n",
    "\n",
    "        if not isinstance(sentences, list):\n",
    "            sentences = list(sentences)\n",
    "        if not isinstance(video_paths, list):\n",
    "            video_paths= list(video_paths)\n",
    "\n",
    "        # Load data\n",
    "        inputs = {\n",
    "            ModalityType.TEXT: data.load_and_transform_text(sentences, device),\n",
    "            ModalityType.VISION: data.load_and_transform_video_data(video_paths, device),\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embeddings = model(inputs)\n",
    "\n",
    "        batch_sentences_embeddings.append(embeddings[ModalityType.TEXT])\n",
    "        batch_videos_embeddings.append(embeddings[ModalityType.VISION])\n",
    "\n",
    "    return batch_sentences_embeddings, batch_videos_embeddings\n",
    "\n",
    "    # Create similarity matrix\n",
    "    sim_matrix = create_sim_matrix(batch_sentences_embeddings, batch_videos_embeddings)\n",
    "\n",
    "    # Log metrics\n",
    "    print(f\"MSRVTT sim matrix size: {sim_matrix.shape[0]}, {sim_matrix.shape[1]}\")\n",
    "    tv_metrics = compute_metrics(sim_matrix)\n",
    "    vt_metrics = compute_metrics(sim_matrix.T)\n",
    "    print('\\t Length-T: {}, Length-V:{}'.format(len(sim_matrix), len(sim_matrix[0])))\n",
    "\n",
    "    print(f\"MSRVTT Text-to-Video:\")\n",
    "    print('\\t>>>  R@1: {:.1f} - R@5: {:.1f} - R@10: {:.1f} - Median R: {:.1f} - Mean R: {:.1f}'.\n",
    "                format(tv_metrics['R1'], tv_metrics['R5'], tv_metrics['R10'], tv_metrics['MR'], tv_metrics['MeanR']))\n",
    "    print(f\"MSRVTT Video-to-Text:\")\n",
    "    print('\\t>>>  V2T$R@1: {:.1f} - V2T$R@5: {:.1f} - V2T$R@10: {:.1f} - V2T$Median R: {:.1f} - V2T$Mean R: {:.1f}'.\n",
    "                format(vt_metrics['R1'], vt_metrics['R5'], vt_metrics['R10'], vt_metrics['MR'], vt_metrics['MeanR']))\n",
    "\n",
    "def create_sim_matrix(batch_sentences_embeddings, batch_videos_embeddings):\n",
    "    \"\"\"Calculate embedding vector product for similarity and download result to CPU\n",
    "    \n",
    "        Returns: \n",
    "            sim_matrix (Text X Video)\n",
    "    \"\"\"\n",
    "    sim_matrix = []\n",
    "    for idx1 in range(len(batch_sentences_embeddings)):\n",
    "        sequence_output = batch_sentences_embeddings[idx1]\n",
    "        each_row = []\n",
    "        for idx2 in range(len(batch_videos_embeddings)):\n",
    "            visual_output = batch_videos_embeddings[idx2]\n",
    "            b1b2 =  sequence_output @ visual_output.T\n",
    "            b1b2 = b1b2.cpu().detach().numpy()\n",
    "            each_row.append(b1b2)\n",
    "        each_row = np.concatenate(tuple(each_row), axis=-1)\n",
    "        sim_matrix.append(each_row)\n",
    "    sim_matrix = np.concatenate(tuple(sim_matrix), axis=0)\n",
    "    return sim_matrix\n",
    "\n",
    "def compute_metrics(x):\n",
    "    sx = np.sort(-x, axis=1)\n",
    "    d = np.diag(-x)\n",
    "    d = d[:, np.newaxis]\n",
    "    ind = sx - d\n",
    "    ind = np.where(ind == 0)\n",
    "    ind = ind[1]\n",
    "    metrics = {}\n",
    "    metrics['R1'] = float(np.sum(ind == 0)) * 100 / len(ind)\n",
    "    metrics['R5'] = float(np.sum(ind < 5)) * 100 / len(ind)\n",
    "    metrics['R10'] = float(np.sum(ind < 10)) * 100 / len(ind)\n",
    "    metrics['MR'] = np.median(ind) + 1\n",
    "    metrics[\"MedianR\"] = metrics['MR']\n",
    "    metrics[\"MeanR\"] = np.mean(ind) + 1\n",
    "    # metrics[\"cols\"] = [int(i) for i in list(ind)]\n",
    "    return metrics\n",
    "\n",
    "def main():\n",
    "    assert torch.cuda.is_available()\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Instantiate model\n",
    "    model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    args = get_args_msrvtt()\n",
    "\n",
    "    dataloader_msrvtt = DataLoader(\n",
    "        MyMSRVTT_DataLoader(csv_path=args.val_csv, features_path=args.features_path),\n",
    "        batch_size=args.batch_size_val,\n",
    "        num_workers=args.num_thread_reader,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    return run_msrvtt_eval(model, dataloader_msrvtt, device)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    batch_sentences_embeddings, batch_videos_embeddings = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSRVTT sim matrix size: 1000, 1000\n",
      "\t Length-T: 1000, Length-V:1000\n",
      "MSRVTT Text-to-Video:\n",
      "\t>>>  R@1: 36.4 - R@5: 58.9 - R@10: 69.7 - Median R: 3.0 - Mean R: 29.0\n",
      "MSRVTT Video-to-Text:\n",
      "\t>>>  V2T$R@1: 29.1 - V2T$R@5: 53.2 - V2T$R@10: 63.8 - V2T$Median R: 5.0 - V2T$Mean R: 34.1\n"
     ]
    }
   ],
   "source": [
    "def calculate_rankings(batch_sentences_embeddings, batch_videos_embeddings):\n",
    "    # Create similarity matrix\n",
    "    sim_matrix = create_sim_matrix(batch_sentences_embeddings, batch_videos_embeddings)\n",
    "\n",
    "    # Log metrics\n",
    "    print(f\"MSRVTT sim matrix size: {sim_matrix.shape[0]}, {sim_matrix.shape[1]}\")\n",
    "    tv_metrics = compute_metrics(sim_matrix)\n",
    "    vt_metrics = compute_metrics(sim_matrix.T)\n",
    "    print('\\t Length-T: {}, Length-V:{}'.format(len(sim_matrix), len(sim_matrix[0])))\n",
    "\n",
    "    print(f\"MSRVTT Text-to-Video:\")\n",
    "    print('\\t>>>  R@1: {:.1f} - R@5: {:.1f} - R@10: {:.1f} - Median R: {:.1f} - Mean R: {:.1f}'.\n",
    "                format(tv_metrics['R1'], tv_metrics['R5'], tv_metrics['R10'], tv_metrics['MR'], tv_metrics['MeanR']))\n",
    "    print(f\"MSRVTT Video-to-Text:\")\n",
    "    print('\\t>>>  V2T$R@1: {:.1f} - V2T$R@5: {:.1f} - V2T$R@10: {:.1f} - V2T$Median R: {:.1f} - V2T$Mean R: {:.1f}'.\n",
    "                format(vt_metrics['R1'], vt_metrics['R5'], vt_metrics['R10'], vt_metrics['MR'], vt_metrics['MeanR']))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    calculate_rankings(batch_sentences_embeddings, batch_videos_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSRVTT sim matrix size: 1000, 1000\\\n",
    "\tLength-T: 1000, Length-V:1000\\\n",
    "MSRVTT Text-to-Video:\\\n",
    "\t>>>  R@1: 36.4 - R@5: 58.9 - R@10: 69.7 - Median R: 3.0 - Mean R: 29.0\\\n",
    "MSRVTT Video-to-Text:\\\n",
    "\t>>>  V2T$R@1: 29.1 - V2T$R@5: 53.2 - V2T$R@10: 63.8 - V2T$Median R: 5.0 - V2T$Mean R: 34.1\\\n",
    "\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagebind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
